{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## update paths to your dataset directories ##\n",
    "\n",
    "dataset_dir = r\"...\\train_val\"\n",
    "path_test = r\"...\\eruption_images\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# load and split\n",
    "train_ds = image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# plot classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# save class names\n",
    "class_names = train_ds_raw.class_names\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds_raw.prefetch(AUTOTUNE)\n",
    "val_ds = val_ds_raw.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(12):\n",
    "        ax = plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        label = int(labels[i])\n",
    "        plt.title(class_names[label])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomTranslation(0.1, 0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base mobile net v2 model\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    #weights=None,\n",
    "    #weights='imagenet',\n",
    ")\n",
    "base_model.trainable = False  # freeze for transf learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build full model\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid',\n",
    "                       kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile for transfer learning\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# train\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=40,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze top layers for finetuning\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recompile\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# train again\n",
    "history2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=40,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_histories(h1, h2):\n",
    "    combined = {}\n",
    "    for key in h1.history:\n",
    "        combined[key] = h1.history[key] + h2.history[key]\n",
    "    return combined\n",
    "\n",
    "combined_history = combine_histories(history1, history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(combined_history['accuracy']) + 1)\n",
    "\n",
    "# accuracy\n",
    "plt.figure()\n",
    "plt.plot(epochs, combined_history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(epochs, combined_history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# AUC\n",
    "plt.figure()\n",
    "plt.plot(epochs, combined_history['auc'], label='Train AUC')\n",
    "plt.plot(epochs, combined_history['val_auc'], label='Val AUC')\n",
    "plt.title('Training & Validation AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# loss\n",
    "plt.figure()\n",
    "plt.plot(epochs, combined_history['loss'], label='Train Loss')\n",
    "plt.plot(epochs, combined_history['val_loss'], label='Val Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# evaluate test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    path_test,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {results[1]:.4f}\")\n",
    "print(f\"Test AUC: {results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "y_pred_probs = model.predict(test_ds)\n",
    "y_pred = (y_pred_probs.flatten() > 0.5).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "labels = ['No Activity', 'Activity']\n",
    "cm_df = pd.DataFrame(cm, index=[f'True {label}' for label in labels],\n",
    "                        columns=[f'Pred {label}' for label in labels])\n",
    "\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(cm_df)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e6b42",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edda2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# prep training and val data\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "# data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomTranslation(0.1, 0.1),\n",
    "])\n",
    "\n",
    "# params\n",
    "dropout_rates = [0.3, 0.5]\n",
    "l2_strengths = [0.001]\n",
    "learning_rates = [0.001, 0.0005]\n",
    "epoch_options = [5, 10]\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "def build_model(dropout_rate, l2_strength):\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        include_top=False, input_shape=(224, 224, 3), weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid',\n",
    "                           kernel_regularizer=regularizers.l2(l2_strength))(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model, base_model\n",
    "\n",
    "# grid search and save all models\n",
    "for dropout, l2_val, lr, epochs in product(dropout_rates, l2_strengths, learning_rates, epoch_options):\n",
    "    print(f\"\\n🔍 Training: dropout={dropout}, l2={l2_val}, lr={lr}, epochs={epochs}\")\n",
    "\n",
    "    model, base_model = build_model(dropout, l2_val)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # train with frozen base model\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=epochs, verbose=2)\n",
    "\n",
    "    # fine tune\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr / 10),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    fine_tune_epochs = 3\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=fine_tune_epochs, verbose=2)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(val_ds, verbose=0)\n",
    "\n",
    "    # save model\n",
    "    model_name = f\"model_d{dropout}_l2{l2_val}_lr{lr}_e{epochs + fine_tune_epochs}.h5\"\n",
    "    model.save(f\"saved_models/{model_name}\")\n",
    "    print(f\"Saved model as {model_name}\")\n",
    "\n",
    "    results.append({\n",
    "        'model': model_name,\n",
    "        'dropout': dropout,\n",
    "        'l2': l2_val,\n",
    "        'lr': lr,\n",
    "        'epochs': epochs + fine_tune_epochs,\n",
    "        'val_accuracy': val_acc\n",
    "    })\n",
    "\n",
    "# save training resutls\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"grid_search_results.csv\", index=False)\n",
    "print(\"\\n models saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac57a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    path_test,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    label_mode='binary'\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for x, y in test_ds], axis=0)\n",
    "\n",
    "# get all model performances\n",
    "df_eval = pd.read_csv(\"all_models_test_evaluation.csv\")\n",
    "best_model_file = df_eval.sort_values(by=\"test_accuracy\", ascending=False).iloc[0][\"model\"]\n",
    "\n",
    "# best modle\n",
    "print(f\"\\nBest Model: {best_model_file}\")\n",
    "\n",
    "model_path = os.path.join(\"saved_models\", best_model_file)\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "y_pred_probs = model.predict(test_ds)\n",
    "y_pred_labels = (y_pred_probs.flatten() > 0.5).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_labels)\n",
    "labels = ['No Activity', 'Activity']\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion Matrix: {best_model_file}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_labels, target_names=labels))\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred_labels)\n",
    "precision = precision_score(y_true, y_pred_labels)\n",
    "recall = recall_score(y_true, y_pred_labels)\n",
    "f1 = f1_score(y_true, y_pred_labels)\n",
    "\n",
    "print(\"Accuracy:\", round(accuracy, 4))\n",
    "print(\"Precision:\", round(precision, 4))\n",
    "print(\"Recall:\", round(recall, 4))\n",
    "print(\"F1 Score:\", round(f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da906b34",
   "metadata": {},
   "source": [
    "# training curves best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d0306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import os\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    label_mode='binary',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(\"all_models_test_evaluation.csv\")\n",
    "df_train = pd.read_csv(\"grid_search_results.csv\")\n",
    "\n",
    "\n",
    "best_model_name = df_test.sort_values(by=\"test_accuracy\", ascending=False).iloc[0][\"model\"]\n",
    "\n",
    "# get hyperparams\n",
    "best_row = df_train[df_train[\"model\"] == best_model_name].iloc[0]\n",
    "\n",
    "dropout = float(best_row[\"dropout\"])\n",
    "l2_val = float(best_row[\"l2\"])\n",
    "lr = float(best_row[\"lr\"])\n",
    "total_epochs = int(best_row[\"epochs\"])\n",
    "fine_tune_epochs = 3\n",
    "initial_epochs = total_epochs - fine_tune_epochs\n",
    "\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Using params -> dropout: {dropout}, l2: {l2_val}, lr: {lr}, epochs: {total_epochs}\")\n",
    "\n",
    "\n",
    "def build_model(dropout_rate, l2_strength):\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        include_top=False, input_shape=(224, 224, 3), weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.2),\n",
    "        layers.RandomZoom(0.2),\n",
    "        layers.RandomContrast(0.2),\n",
    "        layers.RandomTranslation(0.1, 0.1),\n",
    "    ])\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid',\n",
    "                           kernel_regularizer=regularizers.l2(l2_strength))(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model, base_model\n",
    "\n",
    "\n",
    "model, base_model = build_model(dropout, l2_val)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "history1 = model.fit(train_ds, validation_data=val_ds, epochs=initial_epochs, verbose=2)\n",
    "\n",
    "\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr / 10),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history2 = model.fit(train_ds, validation_data=val_ds, epochs=fine_tune_epochs, verbose=2)\n",
    "\n",
    "\n",
    "def combine_history(h1, h2):\n",
    "    combined = {}\n",
    "    for key in h1.history:\n",
    "        combined[key] = h1.history[key] + h2.history[key]\n",
    "    return combined\n",
    "\n",
    "combined_history = combine_history(history1, history2)\n",
    "\n",
    "\n",
    "epochs_range = range(len(combined_history['accuracy']))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, combined_history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(epochs_range, combined_history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, combined_history['loss'], label='Train Loss')\n",
    "plt.plot(epochs_range, combined_history['val_loss'], label='Val Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
